{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f155a05c",
   "metadata": {},
   "source": [
    "### Simple Linear Regression\n",
    "Simple Linear Regression is a statistical method that models the relationship between a dependent variable (Y) and a single independent variable (X) by fitting a straight line.\n",
    "\n",
    "Equation:\n",
    "Y = b0 + b1*X + ε\n",
    "\n",
    "where:\n",
    "- b0 = intercept\n",
    "- b1 = slope\n",
    "- ε = error term\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "98c59bb8",
   "metadata": {},
   "source": [
    "### Key assumptions of Simple Linear Regression\n",
    "1. Linearity – The relationship between X and Y is linear.\n",
    "2. Independence – Observations are independent of each other.\n",
    "3. Homoscedasticity – Constant variance of residuals.\n",
    "4. Normality of errors – Residuals follow a normal distribution.\n",
    "5. No multicollinearity – Not applicable for single predictor, but relevant for multiple regression.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b874b8c0",
   "metadata": {},
   "source": [
    "### Heteroscedasticity\n",
    "Heteroscedasticity occurs when the variance of residuals changes with the value of X.\n",
    "\n",
    "Impact: It can make coefficient estimates inefficient and affect hypothesis testing.\n",
    "\n",
    "Importance: Detecting and correcting it ensures accurate prediction intervals and valid significance tests.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0ca8c91e",
   "metadata": {},
   "source": [
    "### Multiple Linear Regression\n",
    "Multiple Linear Regression models the relationship between a dependent variable and two or more independent variables.\n",
    "\n",
    "Equation:\n",
    "Y = b0 + b1*X1 + b2*X2 + ... + bn*Xn + ε\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ba0e0511",
   "metadata": {},
   "source": [
    "### Polynomial Regression\n",
    "Polynomial Regression is an extension of linear regression where the relationship between independent and dependent variables is modeled as an nth-degree polynomial.\n",
    "\n",
    "Example:\n",
    "Y = b0 + b1*X + b2*X^2 + ... + bn*X^n\n",
    "\n",
    "- Linear regression fits a straight line.\n",
    "- Polynomial regression fits a curved line to capture non-linear trends.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "659e3864",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.linear_model import LinearRegression\n",
    "\n",
    "X = np.array([1, 2, 3, 4, 5]).reshape(-1, 1)\n",
    "Y = np.array([2.1, 4.3, 6.1, 7.9, 10.2])\n",
    "\n",
    "model = LinearRegression()\n",
    "model.fit(X, Y)\n",
    "\n",
    "y_pred = model.predict(X)\n",
    "\n",
    "plt.scatter(X, Y, color='blue')\n",
    "plt.plot(X, y_pred, color='red')\n",
    "plt.title(\"Simple Linear Regression\")\n",
    "plt.xlabel(\"X\")\n",
    "plt.ylabel(\"Y\")\n",
    "plt.show()\n",
    "\n",
    "print(\"Intercept:\", model.intercept_)\n",
    "print(\"Slope:\", model.coef_[0])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6b7f68f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from statsmodels.stats.outliers_influence import variance_inflation_factor\n",
    "\n",
    "Area = [1200, 1500, 1800, 2000]\n",
    "Rooms = [2, 3, 3, 4]\n",
    "Price = [250000, 300000, 320000, 370000]\n",
    "\n",
    "df = pd.DataFrame({'Area': Area, 'Rooms': Rooms, 'Price': Price})\n",
    "\n",
    "X = df[['Area', 'Rooms']]\n",
    "y = df['Price']\n",
    "\n",
    "model = LinearRegression()\n",
    "model.fit(X, y)\n",
    "\n",
    "# VIF Calculation\n",
    "vif_data = pd.DataFrame()\n",
    "vif_data[\"Feature\"] = X.columns\n",
    "vif_data[\"VIF\"] = [variance_inflation_factor(X.values, i) for i in range(X.shape[1])]\n",
    "\n",
    "print(\"VIF Results:\\n\", vif_data)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14c39265",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import PolynomialFeatures\n",
    "\n",
    "X = np.array([1, 2, 3, 4, 5]).reshape(-1, 1)\n",
    "Y = np.array([2.2, 4.8, 7.5, 11.2, 14.7])\n",
    "\n",
    "poly = PolynomialFeatures(degree=2)\n",
    "X_poly = poly.fit_transform(X)\n",
    "\n",
    "model = LinearRegression()\n",
    "model.fit(X_poly, Y)\n",
    "y_pred = model.predict(X_poly)\n",
    "\n",
    "plt.scatter(X, Y, color='blue')\n",
    "plt.plot(X, y_pred, color='red')\n",
    "plt.title(\"Polynomial Regression (Degree 2)\")\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "046e87ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = np.array([10, 20, 30, 40, 50]).reshape(-1, 1)\n",
    "Y = np.array([15, 35, 40, 50, 65])\n",
    "\n",
    "model = LinearRegression()\n",
    "model.fit(X, Y)\n",
    "y_pred = model.predict(X)\n",
    "\n",
    "residuals = Y - y_pred\n",
    "\n",
    "plt.scatter(X, residuals, color='purple')\n",
    "plt.axhline(y=0, color='black', linestyle='--')\n",
    "plt.xlabel(\"X\")\n",
    "plt.ylabel(\"Residuals\")\n",
    "plt.title(\"Residuals Plot\")\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dbdccf20",
   "metadata": {},
   "source": [
    "### Handling heteroscedasticity & multicollinearity\n",
    "1. Addressing heteroscedasticity:\n",
    "   - Use weighted least squares regression.\n",
    "   - Transform dependent variable (log, sqrt).\n",
    "   - Identify and remove outliers if necessary.\n",
    "\n",
    "2. Addressing multicollinearity:\n",
    "   - Check VIF values; remove variables with high VIF (>10).\n",
    "   - Combine correlated variables.\n",
    "   - Use regularization methods like Ridge or Lasso regression.\n",
    "\n",
    "3. Ensure model robustness:\n",
    "   - Cross-validation.\n",
    "   - Residual analysis.\n",
    "   - Feature scaling.\n"
   ]
  }
 ],
 "metadata": {},
 "nbformat": 4,
 "nbformat_minor": 5
}